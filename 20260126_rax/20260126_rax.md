# Rax: Learning-to-Rank with JAX

## 概要

RaxはGoogleが開発したJAXベースのLearning-to-Rank（LTR）ライブラリ。
検索エンジンや推薦システムなど、ランキング問題に特化した損失関数と評価指標を提供する。

論文: [Rax: Composable Learning-to-Rank Using JAX](https://dl.acm.org/doi/10.1145/3534678.3539065) (KDD 2022)

## Learning-to-Rankとは

検索クエリに対して、ドキュメントの関連度順にランキングするモデルを学習するタスク。

```
Query: "JAX tutorial"
    ↓
Documents: [doc1, doc2, doc3, ..., docN]
    ↓
Ranking Model
    ↓
Ranked: [doc3, doc1, doc5, ...] (関連度順)
```

### アプローチの分類

| アプローチ | 説明 | 損失関数例 |
|-----------|------|-----------|
| **Pointwise** | 各ドキュメントの関連度を独立に予測 | MSE, Cross-entropy |
| **Pairwise** | ドキュメントペアの順序関係を学習 | RankNet, Hinge |
| **Listwise** | リスト全体の順序を最適化 | ListMLE, Softmax |

## Raxの主要機能

### 損失関数 (`rax.*_loss`)

```python
import rax

scores = jnp.array([2.2, -1.3, 5.4])  # モデル出力スコア
labels = jnp.array([1.0, 0.0, 2.0])   # 関連度ラベル

# Listwise損失
rax.softmax_loss(scores, labels)      # Softmax cross-entropy
rax.listmle_loss(scores, labels)      # ListMLE

# Pairwise損失
rax.pairwise_logistic_loss(scores, labels)  # RankNet
rax.pairwise_hinge_loss(scores, labels)     # Ranking SVM
```

### 評価指標 (`rax.*_metric`)

```python
# NDCG (Normalized Discounted Cumulative Gain)
rax.ndcg_metric(scores, labels)
rax.ndcg_metric(scores, labels, topn=5)  # NDCG@5

# MRR (Mean Reciprocal Rank)
rax.mrr_metric(scores, labels)

# Precision
rax.precision_metric(scores, labels, topn=3)  # Precision@3
```

### 近似変換 (`rax.*_t12n`)

評価指標を微分可能な損失関数に変換する。

```python
# NDCGを直接最適化
approx_ndcg_loss = rax.approx_t12n(rax.ndcg_metric, temperature=1.0)
loss = approx_ndcg_loss(scores, labels)
```

## アーキテクチャ

### RankingMLP（スコアリングモデル）

```
Input Features [batch, list_size, features]
    ↓
Reshape → [batch * list_size, features]
    ↓
┌─────────────────────────────┐
│ Linear → LayerNorm → GELU  │ × N layers
│         → Dropout          │
└─────────────────────────────┘
    ↓
Linear → [batch * list_size, 1]
    ↓
Reshape → [batch, list_size]
    ↓
Scores (各ドキュメントの関連度スコア)
```

### 学習フロー

```
Documents + Query → Feature Extraction → RankingMLP → Scores
                                                         ↓
Labels (relevance) ─────────────────────────────→ Rax Loss
                                                         ↓
                                              Backpropagation
```

## 実装

- フレームワーク: JAX + Flax NNX + Rax
- 正規化: LayerNorm
- 活性化関数: GELU
- PEP 723対応（`uv run`で単一ファイル実行可能）

### 実行方法

```bash
uv run 20260126_rax.py
```

### ハイパーパラメータ

| パラメータ | デフォルト値 | 説明 |
|-----------|-------------|------|
| `n_features` | 16 | 入力特徴量次元 |
| `hidden_dim` | 64 | 隠れ層次元 |
| `n_layers` | 2 | MLP層数 |
| `list_size` | 10 | クエリあたりのドキュメント数 |
| `loss_type` | softmax | 損失関数の種類 |

### 対応する損失関数

| loss_type | 損失関数 | 特徴 |
|-----------|---------|------|
| `softmax` | Softmax Cross-entropy | Listwise、安定した学習 |
| `pairwise_logistic` | RankNet | Pairwise、ペア比較 |
| `pairwise_hinge` | Ranking SVM | Pairwise、マージン最大化 |
| `listmle` | ListMLE | Listwise、順列確率最大化 |

## 評価指標の解説

### NDCG (Normalized Discounted Cumulative Gain)

ランキング品質の標準指標。上位に関連度の高いドキュメントがあるほど高スコア。

```
DCG = Σ (2^rel_i - 1) / log2(i + 1)
NDCG = DCG / IDCG  (IDCGは理想的なランキングのDCG)
```

### MRR (Mean Reciprocal Rank)

最初の関連ドキュメントの順位の逆数。

```
MRR = 1 / rank_of_first_relevant_doc
```

## 参考

- [GitHub - google/rax](https://github.com/google/rax)
- [Rax: Composable Learning-to-Rank Using JAX (KDD 2022)](https://dl.acm.org/doi/10.1145/3534678.3539065)
- [Google Research Blog](https://research.google/blog/rax-composable-learning-to-rank-using-jax/)
